## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ª**ç ”ç©¶åž‹å®žéªŒä»£ç åº“**ï¼Œç”¨äºŽç ”ç©¶
[RWKV-LM](https://github.com/BlinkDL/RWKV-LM) ä¸­ **RWKV-8 å¼•å…¥çš„ ROSAï¼ˆRapid Online Suffix Automatonï¼‰æœºåˆ¶**ï¼Œé‡ç‚¹å…³æ³¨ï¼š

> **åœ¨ä¿æŒ ROSA ä¸ºç¡®å®šæ€§ã€ç¦»æ•£ã€ç®—æ³•æ¨¡å—çš„å‰æä¸‹ï¼Œå¦‚ä½•å¯¹å…¶è¿›è¡Œå¯è®­ç»ƒçš„æ¢¯åº¦ä¼°è®¡ã€‚**

ROSA æ˜¯ä¸€ç§åŸºäºŽåœ¨çº¿åŽç¼€è‡ªåŠ¨æœºçš„ã€æ— é™ä¸Šä¸‹æ–‡çš„ç¬¦å·è®°å¿†ç»“æž„ï¼Œå…¶å‰å‘æ‰§è¡Œå®Œå…¨æ˜¯ **ç¦»æ•£ä¸”ä¸å¯å¾®çš„**ã€‚æœ¬é¡¹ç›®å°è¯•åœ¨ä¸€ä¸ªæœ€å°å¯æŽ§çš„ toy ä»»åŠ¡ä¸­ï¼Œæ¯”è¾ƒä¸åŒæ¢¯åº¦ä¼°è®¡æ–¹æ³•åœ¨è®­ç»ƒæ­¤ç±»æ¨¡å—æ—¶çš„è¡Œä¸ºã€æ•ˆçŽ‡ä¸Žæ•ˆæžœã€‚

---

## æœ¬é¡¹ç›®åšäº†ä»€ä¹ˆ

* å®žçŽ°äº†ä¸€ä¸ª **æœ€å°å¯è¿è¡Œçš„ ROSA åŽŸåž‹**ï¼ˆPython ç‰ˆï¼Œä¸¥æ ¼ç¦»æ•£ã€ç¡®å®šæ€§ï¼‰ã€‚
* å°† ROSA é€šè¿‡ **1-bit deterministic gateï¼ˆ`x > 0`ï¼‰** åµŒå…¥åˆ°ç¥žç»ç½‘ç»œä¸­ï¼Œä½œä¸ºéšè—æ€çš„ç»“æž„æ€§è¡¥å……ä¿¡å·ã€‚
* åœ¨ä¸€ä¸ªåˆæˆåºåˆ—é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œå¯¹æ¯”ä¸¤ç§æ¢¯åº¦ä¼°è®¡æ–¹æ³•ï¼š

  * **FLIPï¼ˆé€ bit ç¿»è½¬æœ‰é™å·®åˆ†ï¼‰**

    * æ¢¯åº¦è´¨é‡é«˜
    * è®¡ç®—ä»£ä»·æžå…¶æ˜‚è´µï¼ˆO(T) æ¬¡ ROSA è°ƒç”¨ï¼‰
  * **RODEO / DisARM é£Žæ ¼çš„éšæœºæ¢¯åº¦ä¼°è®¡å™¨**

    * ä½¿ç”¨ Bernoulli é‡‡æ ·ä¸Žç›¸å…³é‡‡æ ·é™ä½Žæ–¹å·®
    * æ¯æ­¥åªéœ€ O(1) æ¬¡ ROSA è°ƒç”¨ï¼Œé€Ÿåº¦æå‡çº¦ 1â€“2 ä¸ªæ•°é‡çº§
* å¯¹æ¯”å¹¶è¾“å‡ºï¼š

  * æ¯æ­¥è€—æ—¶
  * è®­ç»ƒ loss æ›²çº¿
  * æœ€ç»ˆ next-token accuracy
  * ROSA æœ¬èº«ä½œä¸º baseline çš„å‡†ç¡®çŽ‡

---

## ä¸Ž RWKV-8 / ROSA çš„å…³ç³»

æœ¬é¡¹ç›®**ä¸æ˜¯ RWKV-8 çš„å®˜æ–¹å®žçŽ°ï¼Œä¹Ÿä¸æ˜¯å®Œæ•´å¤çŽ°**ï¼Œè€Œæ˜¯ä¸€ä¸ªï¼š

* ç”¨äºŽ**ç†è§£å’Œå®žéªŒ** RWKV-8 ä¸­ ROSA æœºåˆ¶çš„æœ€å°ç ”ç©¶æ¡†æž¶
* ç”¨äºŽæŽ¢ç´¢ï¼š

  * ROSA è¿™ç±» **ç¡®å®šæ€§ã€ç¬¦å·åŒ–ã€åŽ†å²ç›¸å…³æ¨¡å—**
  * åœ¨ä¸ä¾èµ–æ³¨æ„åŠ›ã€ä¸ä½¿ç”¨ KV cache çš„æƒ…å†µä¸‹
  * å¦‚ä½•é€šè¿‡ **éžæ ‡å‡†æ¢¯åº¦ä¼°è®¡æ–¹æ³•** ä¸Žç¥žç»ç½‘ç»œååŒè®­ç»ƒ

ç‰¹åˆ«åœ°ï¼š

* æœ¬é¡¹ç›®ä¸­çš„ ROSA **æ˜¯ç¡®å®šæ€§çš„**
* æ‰€ä½¿ç”¨çš„éšæœºæ€§ **ä»…å­˜åœ¨äºŽæ¢¯åº¦ä¼°è®¡é˜¶æ®µ**ï¼Œè€Œéžå‰å‘è®¡ç®—æœ¬èº«

---

## å½“å‰ç»“è®ºï¼ˆé˜¶æ®µæ€§ï¼‰

* FLIP æä¾›äº†æŽ¥è¿‘â€œç²¾ç¡®â€çš„æ¢¯åº¦ï¼Œä½†åœ¨å®žé™…è§„æ¨¡ä¸‹ä¸å¯ç”¨ã€‚
* RODEO/DisARM é£Žæ ¼ä¼°è®¡å™¨å¯ä»¥åœ¨ä¿æŒ forward ä¸å˜çš„æƒ…å†µä¸‹ï¼š

  * å°†è®­ç»ƒé€Ÿåº¦æå‡çº¦ **80â€“100Ã—**
  * ç”±äºŽFLIPé€Ÿåº¦è¿‡æ…¢ï¼Œæˆ‘æ²¡æœ‰åšå¤ªå¤šå¯¹æ¯”å®žéªŒï¼Œä½†åœ¨æˆ‘çš„å°è§„æ¨¡å®žéªŒä¸Šï¼Œä¸¤è€…lossç›¸å½“
* è¿™éªŒè¯äº†ï¼š

  * **ROSA è¿™ç±»ç¦»æ•£ç®—æ³•æ¨¡å—ä½¿ç”¨é«˜æ•ˆæ¢¯åº¦ä¼°è®¡å™¨æ˜¯å¯è®­ç»ƒçš„**
  * æ¢¯åº¦ä¼°è®¡å™¨çš„è®¾è®¡ï¼ˆåå·® / æ–¹å·® / ç›®æ ‡å¯¹é½ï¼‰è‡³å…³é‡è¦

---

## ä»£ç çŠ¶æ€è¯´æ˜Ž

* æœ¬ä»£ç ä»¥**ç ”ç©¶æ¸…æ™°æ€§**ä¸ºä¼˜å…ˆç›®æ ‡
* å¹¶éžé«˜æ€§èƒ½å®žçŽ°
* å¹¶æœªå®Œå…¨å®žçŽ° RODEO åŽŸè®ºæ–‡ä¸­çš„ control variate è®­ç»ƒ

---

## è‡´è°¢ä¸Žå‚è€ƒ

* RWKV-LM: [https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)
* RODEO: *Gradient Estimation with Discrete Stein Operators*

---

## Overview

This repository is a **research-oriented experimental prototype** created to study the **ROSA (Rapid Online Suffix Automaton) mechanism introduced in RWKV-8**, as described in:

ðŸ‘‰ [https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)

The focus of this project is **not** to reimplement RWKV-8 itself, but to investigate:

> **How a deterministic, discrete, history-dependent symbolic module like ROSA can be trained inside neural networks using alternative gradient estimators.**

ROSA is fully discrete, non-differentiable, and algorithmic by design. This makes standard backpropagation inapplicable and motivates the exploration of specialized gradient estimation techniques.

---

## What this project does

* Implements a **minimal, fully deterministic ROSA prototype** (Python, suffix automatonâ€“based).
* Integrates ROSA into a neural model via a **1-bit deterministic gate** (`x > 0`).
* Trains the model on a synthetic sequence prediction task.
* Compares two gradient estimators:

  * **FLIP (finite-difference bit flipping)**

    * Near-exact gradients
    * Prohibitively expensive (O(T) ROSA evaluations per step)
  * **RODEO / DisARM-style stochastic estimators**

    * Based on correlated Bernoulli sampling
    * O(1) ROSA evaluations per step, ~1â€“2 orders of magnitude faster
* Reports:

  * per-step runtime
  * training loss curves
  * final next-token accuracy
  * ROSA baseline accuracy

---

## Relation to RWKV-8 and ROSA

This codebase is **not an official RWKV implementation**.

Instead, it serves as a **controlled research sandbox** to better understand the design space around RWKV-8â€™s ROSA mechanism:

* ROSA is treated as a **deterministic symbolic memory module**, consistent with RWKV-8â€™s philosophy.
* All stochasticity appears **only in the gradient estimation process**, not in forward execution.
* The goal is to explore how such modules can be made trainable without attention, KV caches, or differentiable relaxations.

---

## Current findings (preliminary)

* Exact finite-difference gradients (FLIP) are effective but computationally infeasible.
* Stochastic estimators enable **~80â€“100Ã— speedups** while keeping the forward pass unchanged.
* Due to the slow speed of FLIP, I didn't conduct many experiments. However, in my small-scale experiments, the losses of the two were comparable.

---

## Project status

* Research prototype
* Optimized for clarity and reproducibility, not production use
* Control variate training from the original RODEO paper is not fully implemented

---

## References

* RWKV-LM: [https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)
* *Gradient Estimation with Discrete Stein Operators (RODEO)*
